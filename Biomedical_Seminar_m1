**Scientific Seminar "Biomedical Data Analysis" (rus)**

Synonyms for the course title: Algorithms and Data Structures.

Lecture 1: Basic def. Typical algorithms. Algorithm efficiency. /08.09.2021/

* How to compare the two words: actgc, ctagg?

actgc  a|c|t|_|g|c
ctagg  _|c|t|a|g|g

where "_" - deletions, |_| - insertions (of a, for instance), |c| - replacements.
                       |a|                                    |g|

Case study sample: two proteins that should be compared and analyzed (their structures, relations, etc.).

So, it is important to formalize a biological task.

The reviewed task is named as "alignment" by biologists, "minimization of editorial distances" by mathematicians.

* Alignment can be:
- local or global
- pairwise or multiple.

Case study sample 1: pairwise alignment is used when two seqs exist.
Case study sample 2: local alignemnt is used when we want to compare pieces of DNA (for instance, hundreds bp).
For example, there is a seq consisting of 1B bp. It is needed to find almost the same seqs (the length for each seq is nearly two hundreds bp).
This is very difficult task to solve; thus, it is rarely common.
Case study sample 3: multiple alignment sample - there are 20 proteins instead of 2 ones.
Case study sample 4: global alignment sample - when we want to compare whole seqs.

* Deletions, insertions, replacements may be caused by biological errors (in any biological processes).

* How to find an appropriate alignment? p.s. means w/ a min cost of the editorial operations.
It is possible by use of a graph.

c = > = > = > = > = >.=end
  ^ /*^ / ^ / ^ / ^./ ^
g = > = > = > = >.= > =
  ^ / ^ / ^ / ^/* ^ /*^
t = > = >.=.>.= > = > = 
  ^ / ^./*^ / ^ / ^ / ^
c = >.= > = > = > = > =
  ^./*^ / ^ / ^ / ^ / ^
a.= > = > = > = > = > =
 .^ / ^ / ^ /*^ / ^ / ^
st= > = > = > = > = > =
      c   t   a   g   g
      
* A graph consists of vertices and edges.
>/^ - oriented edges.

It is needed to find such a way from st to end that has /* as much as possible.

Each alignment has its own way on a graph; in contrast, a way on a graph can be referred to an alignment.

a|c|t|_|g|c
_|c|t|a|g|g } - alignment.

The considered task is about the minimization of editorial operations (we do not consider penalties/costs there). 
* If we assume penalties, let's imagine:
Case study sample 1: there are proteins (=> 20 letters alphabet => we get 20x20 matrix). What would be the result, if we replace amino acid 1 into amino acid 2?
If one letter is often replaced by second one, there is a small penalty for such a replacement; in contrast, if it is replaced rarely, it corresponds to a big penalty.
Case study sample 1.1: if we replace amino acid 1 into amino acid 2 (rare combination), there is a risk that an organism will become extinct/be non-viable.

* Needleman-Wunsch algorithm.
.. is an example of dynamic programming, a discipline invented by Richard. Bellman.

For instance, it can be used to find the shortest path on a graph in the case when each arrow has its own length.

c 5 > 4 > 3 > 3 > 3 >.3end
  ^ /*^ / ^ / ^ / ^./ ^
g 4 > 3 > 2 > 2 >.2 > 3
  ^ / ^ / ^ / ^/* ^ /*^
t 3 > 2 >.1.>.2 > 3 > 4 
  ^ / ^./*^ / ^ / ^ / ^
c 2 >.1 > 2 > 3 > 3 > 4
  ^./*^ / ^ / ^ /  / ^
a.1 > 1 > 2 > 2 > 3 > 4
 .^ / ^ / ^ /*^ / ^ / ^
st= > 1 > 2 > 3 > 4 > 5
      c   t   a   g   g  - the main idea to choose minimal value. In this case, an editorial operation equals 1. p.s. an edit. operation for a green arrow equals 0.

* Algorithm complexity.
.. = O(m*n),
where m and n - sizes (word length) of two compared words (m*n matrix).
Let compute the Needleman-Wunsch algorithm complexity:
.. > O(2^m),
where m - size of the smallest word.

32 c 5 > 4 > 3 > 3 > 3 >.3end
    .^./.^./.^./.^./.^./.^
16 g 4 > 3 > 2 > 2 >.2 > 3
    .^./.^./.^./.^./ ^ / ^
8  t 3 > 2 >.1.>.2 > 3 > 4 
    .^./.^./.^./ ^ / ^ / ^
4  c 2 >.1 > 2 > 3 > 3 > 4
    .^./.^./ ^ / ^ / ^ / ^
2  a.1 > 1 > 2 > 2 > 3 > 4
    .^ ./ ^ / ^ /*^ / ^ /^
   st= > 1 > 2 > 3 > 4 > 5 - the left side is considered as the smallest one (it also may be equal to the right side). 
         c   t   a   g   g - the possible ways we have - 2^m.

Case study sample: a protein has 100-300 amino acids, or 300-900 nucleotides.
Let the protein size would be ~ 200 amino acids:
2^(200) = (2^10)^20 [1024] > (1000)^20 = (10^3)^20 = 10^60 variants -> the ways more than 10^60 variants. [2^(200) - each of two proteins with a length of 200.
This is named the curse of dimensionality.

Case study sample: The problem of linear cutting.
L0 - workpiece length, L1,..,Ln - lengths of cut parts. It is needed to minimize waste.
S: *It is possible to solve by dynamic programming method.
Let consider a task series with different L: from 1 to L0.
L1.. | L0-L1 .. ..
So, algorithm complexity is 0(n*L0). 
Solution will be at the Lecture 2.

* Dynamic programming.

Case study sample 1: The problem of hares. Fibonacci numbers.
Hares can cross the swamp on n bumps jumping to the next or through one. Find how many different paths F(n) are possible.
S: Let remind ourselves about Fibonacci seq.: F(n) = F(n-1) + F(n-2) = 1,1,3,5,8,..
Let consider a task series with different n (dif. number of bumps).
Hares get to the last bump in short jumps (F(n-1)) or short jumps (F(n-2)) => F(n) = F(n-1) + F(n-2).
To find F(n), we should compute F(n-1) and F(n-2) at first.
We identify variants when there is/are 1 bump, 2 bumps, 3, etc. -> to the all n bumps.
For instance, there are 100 bumps. Using the Fibonacci formula, we can calculate n(100) = 1,1,2,3,5,8,13,21,44,..n_100. 
This is the sample how algorithms of dynamic programming work.

Case study sample 2: The problem of rabbits.
A pair of rabbits gives birth to another pair every month, starting from the second month from their own birth. How many descendants will one couple have in a year?

Lecture 2: 

Case study sample: alignment (new sample).

2 words - actg, tcgac.  
Insertions and deletions (indels) - 10,  
Replacements a-t, g-c - 5,  
Another replacements - 8.

S: We would like to find the best alignment. To solve it we need to refer to a graph in which to find a path for such alignment. This path should have the shortest length.
According to the editorial operations costs, we get the following result:

g 40 > 30 > 25 > 15 > 21 > 25 .end
   ^ /  ^ /  ^ /  ^ /  ^ /* ^  
t 30 > 20 > 15 > 13 > 20 > 30
   ^ /  ^ /  ^ /  ^ /* ^ /  ^  
c 20 > 15 >  5 >*15 > 25 > 30
   ^ /  ^ /* ^ /  ^ /  ^ /  ^  
a 10 > 5  > 15 > 25 > 30 > 40
   ^ /* ^ /  ^ /  ^ /  ^ /  ^  
   0 > 10 > 20 > 30 > 40 > 50
st.     t    c    g    a   c 

Then, let's create an alignment based on its path:
a c - t g
t c g a c

Case study sample: The problem of linear cutting (from Lecture 1).
<..>
L0 = 8
L1 = 2
L2 = 5

S: It can be solved by dynamic programming method, too.

[0]0 > [1]0 > [2]0 > [3]0 > [4]0 > [5]0 > [6]0 > [7]0 > [8]0
paths on the graph: 0,2; 1,3; 2,4; 3,5; 4,6; 5,7; 6,8; 0,5; 1,6; 2,7; 3,8. These paths have the cost 0, while such ones ">" - 1.
Starting from the end:
[0*]0 > [1]1 > [2*]0 > [3]1 > [4*]0 > [5]0 > [6*]0 > [7]0 > [8*]0
asterisks show the best way to cut this workpiece.

Case study sample: The problem of linear cutting.
L0 - workpiece length, L1,..,Ln - lengths of cut parts. It is needed to minimize waste.
S: *It is possible to solve by dynamic programming method.
Let consider a task series with different L: from 1 to L0.
L1.. | L0-L1 .. ..
So, algorithm complexity is 0(n*L0).

p.s. It is needed to remember the number of correct answers may be more than one, it depends on a case study.

Case study sample: The problem with nonlinear penalties for multiple deletions.
c(m+n) <= c(m) + c(n)
algorithm complexity is 0(L^3).
tip - addition of edges.

Case study sample: Maximum total subsequence.
There are 2 words (sequences), we would like to choose the same subseqs inside of these 2 seqs.
is is worth to note we should not take into account replacements.

atgaccttgaa
\\ \\\  //
cattaccga  , the same letters (nucleotides) are connected by lines.

* Types of alignments:
global multiple alignment.
for instance,
aatggtacac
att__tacac
at_ggtactc
ataggtagt_

pairwise alignment.
aatggtacac
att__tacac

* Sorting


////Solutions will be at the Lecture 3.


